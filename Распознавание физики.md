# Распознавание физики

В данном разделе собраны домыслы автора по возможностям представления и распознавания физических моделей в нейросетях. Рассуждения притянуты без строгих доказательств. Строгое математическое обоснование дается в курсах, из которых составлен данный раздел. Вся структура опирается на аксиоматику Колмогорова, и университетский курс теории функции и функционального анализа, теорию операторов и линейную алгебру, теорию вероятности с аксиоматикой Колмогорова, теорию функции комплексного переменного и множество прикладных курсов, включая теорию линейных стационарных систем, цифровую обработку сигналов, теоретическую физику, теоретическую механику. 

В курсе теории вероятности мы рассматривали представление числовых последовательностей в операторной форме через производящую функцию. 

Любую числовую последовательность можно записать в операторной форме. Операторная форма эквивалентна дискретному Z-пространству полученному через преобразование Лапласа в непрерывном пространстве. Z - пространство естественное представление для численных методов.

Переход от дискретной системы к непрерывной возможен с использованием интерполяции базисными полиномами, в теории функции и математической физике - через обобщенные функции. Обобщенные функции вводятся в курсе теории функции [1] через финитные функции на интервале $[0,1]$.

Дискретная математика и численные методы порождают операторы квантования и дискретизацию. 

Двоичная логика может быть представлена полиномами Жегалкина, - алгебраическая нормальная форма (АНФ) разложения для булевой алгебры, наравне с конъюнктивной и дизъюнктивной нормальной формой разложения для Булевых решеток. Алгебраическую форму разложения можно сводить к базисным полиномам. Необходимо рассмотреть и доказать возможность представления четкой логики в [нечеткой логике](LOGIC.md). 

Между понятием независимые события и разложение по независимым событиям в теории вероятностей (Теоремы Бейеса) и разложением по базисным полиномам в цифровой обработке аналоговых сигналов, разложением по ортогональному базису функций в гильбертовом пространстве, можно провести параллель. Представление непрерывных функций в гильбертовом пространстве и разложение по ортонормированному базису может интерпретироваться в физике, как разложение по плотности вероятности, а сами базисные функции эквивалентны определению плотности вероятности в линейном пространстве квадратично-суммируемых функций. Вся современная физика базируется на теории операторов в линейном пространстве квадратично-суммируемых функций. 

Линейное векторное пространство операторов с квадратичной мерой - Евклидово пространство над множеством вещественных чисел и Гильбертово пространство - бесконечномерное (когда собственные функции могут быть заданы рекуррентно) над множеством комплексных чисел.

Вероятностная логика может иметь разложение в различных базисах, среди которых особое место занимает разложение по базовым полиномам Бернштейна. Вероятностная логика вырождается в четкую логику при использовании предельных значений $\{0,1\}$. 

Дифференциальные уравнения представленные в конечных разностях (в операторной форме) могут быть также разложены по базисным полиномам составленным из операторов. 

В курсе цифровой обработки сигналов мы рассматриваем несколько таких базисов, к которым относятся полиномы Тейлора, Бернштейна, Эрмита, Чебышева и другие. Каждый набор базисных полиномов порождается определенным типом дифференциального уравнения или дифференциальным оператором, например уравнениями эллиптического типа (второго порядка).

Дифференциальные уравнения в операторной форме могут быть представлены в форме рациональных операторов, над которыми действует ассоциативная алгебра с определенной операцией коммутации - коммутатором. На множестве вещественных чисел операторы могут обладать свойством коммутативности или антикоммутативности, что позволяет выполнять преобразования структуры графа. Рациональные операторы (как линейные операторы) могут быть разложены в каскад или сумму и представлены через элементарные дроби, операторы первого и второго порядка (дифференциальные уравнения первого и второго порядка). 

Существует нормальная форма представления операторов в форме системы дифференциальных уравнений первого порядка (нормальная форма) и в форме графа - каскадная (последовательная) форма, композиция операторов. 

Представление дифференциальных уравнений в вычислительных задачах - матрицы, произведение матриц, и матричные экспоненты в моделях с описанием эволюции системы во времени. 

Матрицы можно раскладывать на три: ортогональные (аффинные) преобразования над векторами ($W_x x+b_x$); диагональная $\mathrm{diag}(\lambda_1,..., \lambda_n)$ (трехдиагональная, бидиагональная или ленточная матрица); выходное ортогональное преобразование ($W_y y+b_y$). Для произвольной прямоугольной матрицы $m\times n$ существует сингулярное разложение SVD, и ряд других разложений выявляющих структуру оператора. Сингулярное разложение дает диагональную матрицу и две матрицы преобразования базиса. Интерпретация - всегда существует такой базис, в котором переменные независимы и характеризуются собственными числами. Разложение с трехдиагональной и ленточной матрицей позволяют выявить структуру дифференциального уравнения второго порядка. 

Физика может порождать матрицы специального вида, в том числе симметричные матрицы, унитарные и эрмитовы матрицы. При переходе к галмильтоновой динамике порождаются матрицы анти-симметричные и соответствующие им симплектические "ортогональные" матрицы. 

Системы дифференциальных уравнений порождают трех-диагональные матрицы и матрицы в форме Жордана, с блоками 1х1 и 2х2 на главной диагонали, содержащие действительные и комплексные собственные числа. 

Любая эрмитова матрица по теореме о спектральном разложении может быть представлена, как вещественная диагональная матрица 
$D$, переведённая в другую систему координат (то есть $M=U^{-1}D U$, где $U$ — унитарная матрица, строками которой являются ортонормальные собственные векторы $M$, образующие базис). 


**Разложение существует!**
Первая отправная точка апроксимационная теорема Вейерштрасса: любая функция на компактном множестве $C[0,1]$ может быть приближена полиномами. В доказательстве Бернштейна - существует интерполяция базисными полиномами Бернштейна, которые выведены из биномиального распределения и имеют вероятностную интерпретацию через два события в начальной и конечной точке интервала. Существует множество вариантов представления в разных наборах базисных полиномов, все такие представления данной степени изоморфны и могут быть представлены матрицей - аффинным преобразованием. Аппроксимация на единичном кубике существует и она может быть представлена через базисные сплайны.

Отправная точка теорема KAT Колмогорова-Арнольда, которая справедлива для вещественных функций множества переменных, любая функция на множестве $C[0,1]^n$ может быть представлена, как (сложная функция одного переменного) и сумма. Данное утверждение аналогично сингулярному разложению матрицы - существует такое разложение, которое приводит функцию множества переменных к функции одного переменного. Сингулярное разложение позволяет выделить собственные значения и сжимать матрицы, отбрасывая пренебрежимо малые собственные значения или добавляя новые параметры разложения. 

Объединение этих двух теорем порождает KSN - сети Колмогорова со сплайнами, и KAN - сети на разложении Колмогорова-Арнольда с базисными полиномами Бернштейна (B-сплайнами). Мы взяли современное направление, в которое развилась школа Колмогорова - теория операторов. Научная школа Колмогорова базируется не на пустом месте, имеет свои корни и вектор развития. Сюда следует относить и работы Арнольда (по симплектическим свойствам гамильтоновых систем), и теорию КАМ (Колмогорова — Арнольда — Мозера). 

Принцип Моругина мы ввели, как дифференциальный оператор - добавление еще одного признака, как разложение одного существующего признака на два независимых. Егор Моругин, участвовал в обсуждении принципов построения безразмерной сети и утверждал, что в любое уравнение квантовой физики можно вставить поправку имени Моругина, которая не противоречит уравнению и всякое утверждение, что физика описывается именно таким уравнением не является догмой. Способ расширения матрицы оператора через дифференциальный оператор $\mu$ мы назвали - принцип Моругина. Принцип является рекурсивным и приводит к операторной форме разложения на полиномах со структурой базисных полиномов Бернштейна, т.е. модель может быть описана сплайнами. 

В нашем курсе мы бездоказательно утверждаем, что любую физическую задачу можно представить, как разложение на три преобразования: входное аффинное преобразование вектора, граф рациональных операторов, выходное аффинное преобразование. Таким образом можно предложить некоторую архитектуру вычислительной сети ориентированную на параллельные высокопроизводительные вычисления. Архитектура позволяет решать задачи большим числом обобщенных переменных, а методы разложения позволяют выполнять преобразования из нечеткой логики в четкую, из матричной формы в физические системы в форме дифференциальных уравнений и наоборот выполнить разложение существующей системы дифференциальных уравнений в форму графа нейронной сети. Элементом нейронной сети является квантовый оператор, оператор включающий функцию квантизации (вместо активации). Типы операторов и разложение операторов на элементарные векторные n-мерные операторы мы рассматриваем в курсе. 

Элементом вычислительной архитектуры является "вычислительное ядро" оператора, т.е. некоторая функция, которая выполняет элементарную операцию над разложением тензора входных данных и порождает тензор. Мы рассматриваем относительно новое представление - расчет фрагмента безмасштабной сети - фрагмента графа, состоящего из "ядер" и потока тензоров в дискретном времени с учетом квантования тензоров. 

Немного обособленным кажется преобразование логики высказываний в нечеткую логику и далее представление в форме дифференциальных операторов и элементов архитектуры вычислительной сети. 

Все эти преобразования обратимы! Обратимы в дискретном времени при сохранении информации о состоянии системы. Обратимость - свойство квантовых систем и свойство рациональных операторов. Обратимость - свойство гамильтоновых динамических систем.

## Линейный оператор. Операторы в евклидовом пространстве

Линейное векторное пространство определенное над полем $\mathbb{R}^n$ называется евклидовым, если каждой упорядоченной паре векторов сопоставлено некоторое число - скалярное произведение, удовлетворяющее аксиомам:
1. положительная определенность
2. симметричность 
3. линейность по первому аргументу (линейность по второму - следствие симметрии)

Скалярное произведение определяет норму $\|x\| = \sqrt{(x,x)}$. 

Расстояние между векторами определяется через норму $d(x,y) = \|x - y\|$.

см. 8 Операторы в стр. 249

Понятие оператора тесно связано со скалярным произведением, мне сложно в полной мере осознать утверждение, но как только в уравнении присутствуют частные производные можно применить разложение по ортогональным векторам - перейти к матрицам и линейной алгебре. 

**Матрица Грама** Матрицей Грама системы векторов $\{e_j\}_1^n$ в евклидовом пространстве называется квадратная симметрическая матрица $G$, составленная из скалярных произведений этих векторов
```math
G = \begin{bmatrix}
(e_1,e_1) & (e_1, e_2) & \ldots & (e_1,e_n)\\
(e_2,e_1) & (e_2, e_2) & \ldots & (e_2,e_n)\\
 \vdots   &  \vdots    & \ddots & \vdots \\
(e_n,e_1) & (e_n, e_2) & \ldots & (e_n,e_n)
\end{bmatrix}
``` 

**Матрица линейного оператора**

Матрица $\mathsf{A}$ оператора $\mathcal{A}$, записанная в ортонормированном базисе $\{e_k\}_{k=1}^n$ составлена из элементов
```math
a_{i,j} = (\mathcal{A} e_i, e_j)
```

*матрица линейного оператора строиться также как ми матрица Грамма, через скалярное произведение.*

**Сопряженный оператор** 
Операторы $\mathcal{A}$ и $\mathcal{B}$ действующие в евклидовом пространстве $\mathcal{A}, \mathcal{B}:\mathbb{R}^n \mapsto \mathbb{R}^n$, называются _сопряженными_, если для любых векторов $x,y \in \mathbb{R}^n$ выполняется соотношение $(\mathcal{A}x, y) = (x, \mathcal{B}y)$

*Теорема* Если $\mathcal{A}, \mathcal{B}$ сопряженные операторы действующие в евклидовом пространстве, то в любом ортонормированном базисе их матрицы связаны соотношением $A=B^{\mathsf{T}}$

Заметим, что свойства сопряженных матриц определяется относительно операции скалярного произведения. Применительно к комплексным пространствам сопряженные матрицы будут удовлетворять соотношению $A=B^{\mathsf{H}}$ - эрмитово сопряженные матрицы. Также относительно скалярного произведения вводятся анти-симметрические (skew-symmetric) матрицы ($A = -A^{\mathsf{T}}$) в симплектическом пространстве. Свойство сопряжения определяется аксиомой симметрии скалярного произведения.

## Нормальная форма представления систем дифференциальных уравнений


[] Ю.П. Вирченко, А.В. Субботин О СОВПАДЕНИИ КЛАССОВ СПЕКТРАЛЬНО ОБРАТИМЫХ
И ГАМИЛЬТОНОВЫХ АВТОНОМНЫХ ДИНАМИЧЕСКИХ СИСТЕМ.

[] Вирченко Ю.П., Субботин А.В. Конечномерные спектрально-обратимые динамические системы

Рассмотрим систему обыкновенных дифференциальных уравнений 
```math
\dot{X} = F(X)
```
где $X \in \mathbb{R}^{2n}$ - четно-мерный вектор обобщенных координат. Решением уравнения является векторная функция (траектория) $X(t)$.

Система называется _гамильтоновой в канонической форме_, если отображение F представимо в форме
```math
F_j(X) = J_{jk} \frac{\partial H(X)}{\partial x_k}~, \quad 
J = \begin{pmatrix}0 &-I_n\\I_n&0\end{pmatrix}
``` 
*Заметим, в этом месте можно было бы перейти к комплексным эрмитовым матрицам, приняв X(t)=Q(t)+jP(t).*
*Мнимую единицу можно выразить, как матрицу перестановки J, и перейти к матричной форме уравнений.*

Некоторые исторические представления гамильтоновых систем через дифференциальные операторы мы рассматривали в обзоре по [кватернионам и дифференциальным операторам](QUAT.md). 

## Гамильтоновы системы

Гамильтонова система порождается гамильтонианом $H$ векторной функцией (функционалом или оператором), представляет собой систему 2n обыкновенных дифференциальных уравнений с постоянными коэффициентами для векторных функций $X(t) = [P(t),Q(t)]$ от времени. 
```math
\dot{P} = -{\partial H \over \partial Q}~,\quad 
\dot{Q} =  {\partial H \over \partial P}
```

```math
\begin{pmatrix} \dot{P}\\ \dot{Q} \end{pmatrix} = \mathcal{G}
\begin{pmatrix} P\\ Q \end{pmatrix}
```
где $\mathcal{G}$ - генератор  группы сдвигов по времени, матрица из операторов имеет вид
```math
\dot{X} = \mathcal{G}X~, \quad
\mathcal{G} =
\begin{bmatrix} -\mathcal{B}^{\mathsf{T}} & -\mathcal{C}\\ \mathcal{A} & \mathcal{B} \end{bmatrix}
```
где $A,B,C \in \mathbb{R}^{n\times n}$ - квадратные матрицы, $A=A^{\mathsf{T}}$, $C=C^{\mathsf{T}}$ - симметричные матрицы.

Явные выражения для матричных элементов $n\times n$:
```math
A_{ij} = \frac{\partial^2 H}{\partial{p_i}\partial{p_j}}~,\quad
B_{ij} = \frac{\partial^2 H}{\partial{p_i}\partial{q_j}}~,\quad
C_{ij} = \frac{\partial^2 H}{\partial{q_i}\partial{q_j}}
```


Симплектическую структуру можно определить на любом чётномерном векторном пространстве. 

**Канонический базис**

Для чётномерного пространства мы вводим базис
$(\mathbf{p}_{1},\dots , \mathbf{p}_{n}, \mathbf{q}_{1}, \dots ,\mathbf{q}_{n} )$,
такой что
```math
\left\langle \mathbf{p}_{i} ,\mathbf{q}_{j} \right\rangle =\delta_{ij}~,\quad\left\langle \mathbf{q}_{i},\mathbf{q}_{j} \right\rangle =\left\langle \mathbf{p}_{i} ,\mathbf{p}_{j} \right\rangle =0
```
где $\delta_{ij}$ — символ Кронекера. Он называется _каноническим базисом_ или _базисом Дарбу_.

В каноническом базисе матрица симплектической формы (матрица Грама, состоит из "косых" скалярных произведений) примет вид:
```math
J_{n}={\begin{bmatrix}0&I_{n}\\
-I_{n}&0
\end{bmatrix}}
```
где $I_{n}$ — единичная матрица порядка $n$. 
$J_{n}$ является симплектической матрицей.

Матрица линейного оператора $\hat{H}$ в канонических координатах $\langle\hat{H}e_i, e_j\rangle$ примет привычный вид канонических уравнений гамильтоновой динамики. Все симплектические пространства одинаковой размерности симплектически изоморфны. Это значит что можно найти такое симплектически ортогональное преобразование, что матрица оператора приводится к каноническому базису.

Вектор $X(t) = Q(t) + j P(t)$ можно представить иначе $[Q(t), P(t)]$

```math
\begin{pmatrix} \dot{Q}\\ \dot{P} \end{pmatrix} = \mathcal{G}
\begin{pmatrix} Q\\ P \end{pmatrix}
```
```math
\mathcal{G} =
\begin{bmatrix} \mathcal{B} & \mathcal{A}\\ \mathcal{C} & -\mathcal{B}^{\mathsf{T}} \end{bmatrix}~,\quad 
J = \begin{bmatrix} 0 & I_n \\ -I_n & 0 \end{bmatrix}
```
такой порядок принят в англоязычной литературе. Эквивалентное определение гамильтоновой матрице можно дать через свойство симметрии, где $J$ единичная кососимметричная матрица 
$$HJ = (HJ)^{\mathsf{T}}$$

Анти-гамильтоновы (skew-hamiltonian) матрицы определяются свойством
$$WJ = -(WJ)^{\mathsf{T}}$$

Матрица $\mathcal{G}$ строится аналогично [Хессиану функции(оператор)](https://en.wikipedia.org/wiki/Hessian_matrix), дифференциальный оператор второго порядка, построенный аналогично [Якобиану (оператору)](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant). Якобиан - матрица составленная из частных производных векторной функции от векторного переменного. Якобиан - обобщение понятия производной для векторной функции с пределом (сходимостью) по норме.
```math
\mathbf {f} (\mathbf {x} )-\mathbf {f} (\mathbf {p} )=\mathbf{J}_{\mathbf {f} }(\mathbf {p} )(\mathbf {x} -\mathbf {p} )+o(\|\mathbf {x} -\mathbf {p} \|)\quad (\text{при }\mathbf{x} \to \mathbf{p}),
```
где o(‖x − p‖) - ошибка округления, стремится к нулю. 


Пусть $\mathbf{f} : \mathbb{R}^n \mapsto \mathbb{R}^m$ векторная функция для которой существуют все частные производные на $\mathbb{R}^n$. Якобианом -матрицей от векторной функции $\mathbf{f}$, называется матрица $\mathbf{J}_\mathbf{f} \in \mathbb{R}^{m\times n}$, элементы которой $(\mathbf{J_{\mathbf{f}}})_{i,j} = \cfrac{\partial f_{i}}{\partial x_{j}}$, или в матричной форме
```math
\mathbf {J_{f}} ={\begin{bmatrix}{\dfrac {\partial \mathbf {f} }{\partial x_{1}}}&\cdots &{\dfrac {\partial \mathbf {f} }{\partial x_{n}}}\end{bmatrix}}={\begin{bmatrix}\nabla ^{\mathsf {T}}f_{1}\\\vdots \\\nabla ^{\mathsf {T}}f_{m}\end{bmatrix}}={\begin{bmatrix}{\dfrac {\partial f_{1}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{1}}{\partial x_{n}}}\\\vdots &\ddots &\vdots \\{\dfrac {\partial f_{m}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{m}}{\partial x_{n}}}\end{bmatrix}}
```
где $\nabla^{\mathsf{T}}f_{i}$ транспонированный (вектор-строка) градиент $i$-ой компоненты векторной функции.

Якобиан от композиции функций $f : \mathbb{R}^n \mapsto \mathbb{R}^m$ и $g : \mathbb{R}^m \mapsto \mathbb{R}^k$ удовлетворяет правилу разложения в каскад, формально
```math
\mathbf {J} _{\mathbf {g} \circ \mathbf {f} }(\mathbf {x} )=\mathbf {J} _{\mathbf {g} }(\mathbf {f} (\mathbf {x} ))\mathbf {J} _{\mathbf {f} }(\mathbf {x} )
```
для $\mathbf{x} \in \mathbb{R}^n$.

Якобиан от градиента скалярной функции множества переменных - хессиан, строится как вторая обобщенная производная функции.

$$(\mathbf{H}_{{f}})_{i,j}={\frac{\partial ^{2}f}{\partial x_{i}\,\partial x_{j}}}~.$$


The Hessian matrix of a function $f$ is the transpose of the Jacobian matrix of the gradient of the function $f$: 
```math
\displaystyle \mathbf {H} (f(\mathbf {x} ))=\mathbf {J} (\nabla f(\mathbf {x} ))^{\mathsf {T}}.
```

*Теорема №1* Спектр матрицы $\mathcal{G}$ симметричен относительно нуля.

В условиях, когда матрица не имеет кратных собственных значений и спектр симметричен относительно нуля $\lambda_i = -\lambda_k$, матрица $\mathcal{G}$ - спектрально обратимая, и динамическая система спектрально обратимая. 

*Теорема №2* Каждая гамильтонова матрица размемерности $2n$ со структурой 
```math
G = \begin{pmatrix} -B^{\mathsf{T}} & C \\ A & B \end{pmatrix}
```
где $A,B,C$ - блоки рзамером $n \times n$, матрицы A,C - симметричны, является спектрально-обратимой.



Это утверждение надо понимать, как возможность разложения матрицы и приведения к диагональному виду, со скалярами на главной диагонали (см. спектральное разложение матриц и разложение Шура). Для гамильтоновых матриц всегда существует обратная и существует возможность построения системы дифференциальных уравнений описывающей обратимое во времени преобразование. Это центральное свойство квантовых систем и квантовых вычислений. 



Обратимость квантовых вычислений требует обратимости от каскадного разложения сложной функции. Обратная функция также может быть разложена в каскад.

## Гамильтоновы матрицы

Смежный класс матриц - симплекстические. 

*Определение* Матрица $S \in \mathbb{R}^{2n\times 2n}$ удовлетворяющая тождеству $S^{\mathsf{T}}JS = SJS^{\mathsf{T}} = J$ называется симплектической. И обладает свойством - не меняет структуру гамильтоновой матрицы. 

Для численных методов разложения определяется класс _симплектических ортогональных_ матриц, которые одновременно удовлетворяют двум тождествам: $U^{\mathsf{T}}J U = J$ и $U^{\mathsf{T}}U = I$. Откуда следует тождество $JUJ = U$ и общая блочная структуруа всех ортогональных симплектических матриц
```math
U = \begin{bmatrix} U_1 & U_2\\ -U_2 & U_1\end{bmatrix}~, \quad U_1, U_2 \in \mathbb{R}^{n \times n}.
```

Для вычисления QR разложения матрицы применяются симплекстические аналгори поворотов Гивенса и отражений Хаусхолдера. 

*Теорема (разложение Шура для вещественных матриц)* 
Если $A \in \mathbb{R}^{n\times n}$, существует такая ортогональная матрица что 
```math
Q^{\mathsf{T}}AQ = R= 
\begin{bmatrix}
R_{11} & R_{12} & \ldots & R_{1m}\\
       & R_{22} & \ldots & R_{2m}\\
       &        & \ddots & \vdots\\  
       &        &        & R_{mm}
\end{bmatrix}
```
где $R \in \mathbb{R}^{n\times n}$ - квази диагональная матрица, у которой на главной диагонали раполагаются блоки $R_{ii}$ размером 1x1 с вещественным собственным значением $\lambda_i$ или 2x2 с комплексно-сопряженной парой собственных значений $\lambda_i$ и $\bar{\lambda}_i$. 

[1201.5055v1] 

## Матричная экспонента. Эволюция системы

## Представление цифровых фильтров c БИХ